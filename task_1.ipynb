{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "<div style=\"max-width: 50%;\">\n",
    "<details>\n",
    "    <summary>Details</summary>    \n",
    "    As discussed during Lecture 2, the first phase of a Data Mining project typically includes getting familiar with the domain and pre-processing the dataset in a suitable manner. In this\n",
    "    part of the assignment, we will go through those steps.\n",
    "</details>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 a\n",
    "<div style=\"max-width: 50%;\">\n",
    "<details>\n",
    "    <summary>Detail</summary>    \n",
    "    Start with exploring the raw data that is available: <br><br>\n",
    "    - Notice all sorts of properties of the dataset: how many records are there, how many\n",
    "    attributes, what kinds of attributes are there, ranges of values, distribution of values,\n",
    "    relationships between attributes, missing values, and so on. A table is often a suitable\n",
    "    way of showing such properties of a dataset. Notice if something is interesting (to you,\n",
    "    or in general), make sure you write it down if you find something worth mentioning.<br><br>\n",
    "    - Make various plots of the data. Is there something interesting worth reporting? Re-\n",
    "    port the figures, discuss what is in them. What meaning do those bars, lines, dots, etc.\n",
    "    convey? Please select essential and interesting plots for discussion, as you have limited\n",
    "    space for reporting your findings.\n",
    "</details>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-02-26 13:00:00.000</td>\n",
       "      <td>mood</td>\n",
       "      <td>6.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-02-26 15:00:00.000</td>\n",
       "      <td>mood</td>\n",
       "      <td>6.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-02-26 18:00:00.000</td>\n",
       "      <td>mood</td>\n",
       "      <td>6.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-02-26 21:00:00.000</td>\n",
       "      <td>mood</td>\n",
       "      <td>7.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-02-27 09:00:00.000</td>\n",
       "      <td>mood</td>\n",
       "      <td>6.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376907</th>\n",
       "      <td>2770399</td>\n",
       "      <td>AS14.30</td>\n",
       "      <td>2014-04-11 07:51:16.948</td>\n",
       "      <td>appCat.weather</td>\n",
       "      <td>8.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376908</th>\n",
       "      <td>2772465</td>\n",
       "      <td>AS14.30</td>\n",
       "      <td>2014-04-19 11:00:32.747</td>\n",
       "      <td>appCat.weather</td>\n",
       "      <td>3.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376909</th>\n",
       "      <td>2774026</td>\n",
       "      <td>AS14.30</td>\n",
       "      <td>2014-04-26 10:19:07.434</td>\n",
       "      <td>appCat.weather</td>\n",
       "      <td>7.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376910</th>\n",
       "      <td>2774133</td>\n",
       "      <td>AS14.30</td>\n",
       "      <td>2014-04-27 00:44:48.450</td>\n",
       "      <td>appCat.weather</td>\n",
       "      <td>23.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376911</th>\n",
       "      <td>2784435</td>\n",
       "      <td>AS14.32</td>\n",
       "      <td>2014-04-07 18:25:14.036</td>\n",
       "      <td>appCat.weather</td>\n",
       "      <td>22.431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>376912 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0       id                     time        variable   value\n",
       "0                1  AS14.01  2014-02-26 13:00:00.000            mood   6.000\n",
       "1                2  AS14.01  2014-02-26 15:00:00.000            mood   6.000\n",
       "2                3  AS14.01  2014-02-26 18:00:00.000            mood   6.000\n",
       "3                4  AS14.01  2014-02-26 21:00:00.000            mood   7.000\n",
       "4                5  AS14.01  2014-02-27 09:00:00.000            mood   6.000\n",
       "...            ...      ...                      ...             ...     ...\n",
       "376907     2770399  AS14.30  2014-04-11 07:51:16.948  appCat.weather   8.032\n",
       "376908     2772465  AS14.30  2014-04-19 11:00:32.747  appCat.weather   3.008\n",
       "376909     2774026  AS14.30  2014-04-26 10:19:07.434  appCat.weather   7.026\n",
       "376910     2774133  AS14.30  2014-04-27 00:44:48.450  appCat.weather  23.033\n",
       "376911     2784435  AS14.32  2014-04-07 18:25:14.036  appCat.weather  22.431\n",
       "\n",
       "[376912 rows x 5 columns]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('dataset_mood_smartphone.csv')\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'id', 'time', 'variable', 'value'], dtype='object')"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(data['time'], data['variable'], 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     376912\n",
       "unique        19\n",
       "top       screen\n",
       "freq       96578\n",
       "Name: variable, dtype: object"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['variable'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRY IMPUTE BEFORE AGGREGATING \n",
    "#chat gpt advice - better to aggregate first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.pivot_table(data, values='value', index=['id','time'], columns='variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table.to_csv('table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>variable</th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>activity</th>\n",
       "      <th>appCat.builtin</th>\n",
       "      <th>appCat.communication</th>\n",
       "      <th>appCat.entertainment</th>\n",
       "      <th>appCat.finance</th>\n",
       "      <th>appCat.game</th>\n",
       "      <th>appCat.office</th>\n",
       "      <th>appCat.other</th>\n",
       "      <th>...</th>\n",
       "      <th>appCat.travel</th>\n",
       "      <th>appCat.unknown</th>\n",
       "      <th>appCat.utilities</th>\n",
       "      <th>appCat.weather</th>\n",
       "      <th>call</th>\n",
       "      <th>circumplex.arousal</th>\n",
       "      <th>circumplex.valence</th>\n",
       "      <th>mood</th>\n",
       "      <th>screen</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-02-17 12:04:42.394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-02-17 18:28:25.520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-02-18 09:29:51.257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-02-19 14:43:30.575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-02-19 17:29:10.378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358921</th>\n",
       "      <td>AS14.33</td>\n",
       "      <td>2014-05-30 22:32:05.016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358922</th>\n",
       "      <td>AS14.33</td>\n",
       "      <td>2014-05-30 22:32:11.049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358923</th>\n",
       "      <td>AS14.33</td>\n",
       "      <td>2014-05-30 22:32:14.240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358924</th>\n",
       "      <td>AS14.33</td>\n",
       "      <td>2014-05-30 22:32:15.246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358925</th>\n",
       "      <td>AS14.33</td>\n",
       "      <td>2014-05-31 12:00:00.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>358926 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "variable       id                     time  activity  appCat.builtin  \\\n",
       "0         AS14.01  2014-02-17 12:04:42.394       NaN             NaN   \n",
       "1         AS14.01  2014-02-17 18:28:25.520       NaN             NaN   \n",
       "2         AS14.01  2014-02-18 09:29:51.257       NaN             NaN   \n",
       "3         AS14.01  2014-02-19 14:43:30.575       NaN             NaN   \n",
       "4         AS14.01  2014-02-19 17:29:10.378       NaN             NaN   \n",
       "...           ...                      ...       ...             ...   \n",
       "358921    AS14.33  2014-05-30 22:32:05.016       NaN             NaN   \n",
       "358922    AS14.33  2014-05-30 22:32:11.049       NaN           3.122   \n",
       "358923    AS14.33  2014-05-30 22:32:14.240       NaN           1.003   \n",
       "358924    AS14.33  2014-05-30 22:32:15.246       NaN           4.134   \n",
       "358925    AS14.33  2014-05-31 12:00:00.000       NaN             NaN   \n",
       "\n",
       "variable  appCat.communication  appCat.entertainment  appCat.finance  \\\n",
       "0                          NaN                   NaN             NaN   \n",
       "1                          NaN                   NaN             NaN   \n",
       "2                          NaN                   NaN             NaN   \n",
       "3                          NaN                   NaN             NaN   \n",
       "4                          NaN                   NaN             NaN   \n",
       "...                        ...                   ...             ...   \n",
       "358921                     NaN                   NaN             NaN   \n",
       "358922                     NaN                   NaN             NaN   \n",
       "358923                     NaN                   NaN             NaN   \n",
       "358924                     NaN                   NaN             NaN   \n",
       "358925                     NaN                   NaN             NaN   \n",
       "\n",
       "variable  appCat.game  appCat.office  appCat.other  ...  appCat.travel  \\\n",
       "0                 NaN            NaN           NaN  ...            NaN   \n",
       "1                 NaN            NaN           NaN  ...            NaN   \n",
       "2                 NaN            NaN           NaN  ...            NaN   \n",
       "3                 NaN            NaN           NaN  ...            NaN   \n",
       "4                 NaN            NaN           NaN  ...            NaN   \n",
       "...               ...            ...           ...  ...            ...   \n",
       "358921            NaN            NaN           NaN  ...            NaN   \n",
       "358922            NaN            NaN           NaN  ...            NaN   \n",
       "358923            NaN            NaN           NaN  ...            NaN   \n",
       "358924            NaN            NaN           NaN  ...            NaN   \n",
       "358925            NaN            NaN           NaN  ...            NaN   \n",
       "\n",
       "variable  appCat.unknown  appCat.utilities  appCat.weather  call  \\\n",
       "0                    NaN               NaN             NaN   1.0   \n",
       "1                    NaN               NaN             NaN   1.0   \n",
       "2                    NaN               NaN             NaN   1.0   \n",
       "3                    NaN               NaN             NaN   1.0   \n",
       "4                    NaN               NaN             NaN   1.0   \n",
       "...                  ...               ...             ...   ...   \n",
       "358921               NaN             6.019             NaN   NaN   \n",
       "358922               NaN               NaN             NaN   NaN   \n",
       "358923               NaN               NaN             NaN   NaN   \n",
       "358924               NaN               NaN             NaN   NaN   \n",
       "358925               NaN               NaN             NaN   NaN   \n",
       "\n",
       "variable  circumplex.arousal  circumplex.valence  mood  screen  sms  \n",
       "0                        NaN                 NaN   NaN     NaN  NaN  \n",
       "1                        NaN                 NaN   NaN     NaN  NaN  \n",
       "2                        NaN                 NaN   NaN     NaN  NaN  \n",
       "3                        NaN                 NaN   NaN     NaN  NaN  \n",
       "4                        NaN                 NaN   NaN     NaN  NaN  \n",
       "...                      ...                 ...   ...     ...  ...  \n",
       "358921                   NaN                 NaN   NaN     NaN  NaN  \n",
       "358922                   NaN                 NaN   NaN     NaN  NaN  \n",
       "358923                   NaN                 NaN   NaN     NaN  NaN  \n",
       "358924                   NaN                 NaN   NaN     NaN  NaN  \n",
       "358925                  -2.0                 1.0   7.0     NaN  NaN  \n",
       "\n",
       "[358926 rows x 21 columns]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 1B - OUTLIERS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mood: 397 outliers detected (Lower Bound: 5.5, Upper Bound: 9.5)\n",
      "circumplex.arousal: 0 outliers detected (Lower Bound: -4.0, Upper Bound: 4.0)\n",
      "circumplex.valence: 30 outliers detected (Lower Bound: -1.5, Upper Bound: 2.5)\n",
      "activity: 2223 outliers detected (Lower Bound: -0.2374999999999995, Upper Bound: 0.3958333333333325)\n",
      "screen: 10055 outliers detected (Lower Bound: -80.5047501623631, Upper Bound: 148.36725029349333)\n",
      "appCat.builtin: 10152 outliers detected (Lower Bound: -9.833000000000002, Upper Bound: 21.775000000000002)\n",
      "appCat.communication: 6401 outliers detected (Lower Bound: -55.168625000000006, Upper Bound: 105.862375)\n",
      "appCat.entertainment: 4517 outliers detected (Lower Bound: -19.048000000000002, Upper Bound: 35.304)\n",
      "appCat.finance: 118 outliers detected (Lower Bound: -20.052500000000006, Upper Bound: 44.279500000000006)\n",
      "appCat.game: 85 outliers detected (Lower Bound: -150.06750000000002, Upper Bound: 287.8405)\n",
      "appCat.office: 848 outliers detected (Lower Bound: -7.055625000000001, Upper Bound: 17.103375)\n",
      "appCat.other: 1000 outliers detected (Lower Bound: -7.6963750000000015, Upper Bound: 31.544625000000003)\n",
      "appCat.social: 1838 outliers detected (Lower Bound: -90.483, Upper Bound: 174.885)\n",
      "appCat.travel: 181 outliers detected (Lower Bound: -58.124624999999995, Upper Bound: 110.438375)\n",
      "appCat.unknown: 80 outliers detected (Lower Bound: -54.10074999999999, Upper Bound: 103.54924999999999)\n",
      "appCat.utilities: 182 outliers detected (Lower Bound: -21.10025, Upper Bound: 43.589749999999995)\n",
      "appCat.weather: 10 outliers detected (Lower Bound: -16.313499999999998, Upper Bound: 50.3465)\n",
      "-----------------\n",
      "FOR NOW, OUTLIERS NOT REMOVED, BOUNDARIES NEED TO BE ADJUSTED\n",
      "IDEA, RE-SCALE OUT OF BOUNDS VALUES TO THE NEAREST EXTREME: e.g: BOUND = -2 AND 2, VAL = -3 --> -2\n"
     ]
    }
   ],
   "source": [
    "#TASK 1B - 1 - remove outliers\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = table\n",
    "\n",
    "# List of columns to check for outliers based on the provided information\n",
    "columns_to_check = [\n",
    "    'mood', 'circumplex.arousal', 'circumplex.valence', 'activity', \n",
    "    'screen', 'appCat.builtin', 'appCat.communication', 'appCat.entertainment',\n",
    "    'appCat.finance', 'appCat.game', 'appCat.office', 'appCat.other', \n",
    "    'appCat.social', 'appCat.travel', 'appCat.unknown', 'appCat.utilities',\n",
    "    'appCat.weather'\n",
    "]\n",
    "\n",
    "# Function to calculate IQR and determine outliers\n",
    "def detect_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Determine outliers\n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "    return outliers.shape[0], lower_bound, upper_bound\n",
    "\n",
    "# Dictionary to hold the outlier detection results\n",
    "outlier_detection_results = {}\n",
    "\n",
    "# Analyze each column for outliers\n",
    "for column in columns_to_check:\n",
    "    # Skip the column if it's not in the dataframe\n",
    "    if column not in data.columns:\n",
    "        continue\n",
    "    # Apply the outlier detection\n",
    "    num_outliers, lower_bound, upper_bound = detect_outliers(data, column)\n",
    "    outlier_detection_results[column] = {\n",
    "        \"num_outliers\": num_outliers,\n",
    "        \"lower_bound\": lower_bound,\n",
    "        \"upper_bound\": upper_bound\n",
    "    }\n",
    "\n",
    "# Print the results\n",
    "for column, results in outlier_detection_results.items():\n",
    "    print(f\"{column}: {results['num_outliers']} outliers detected \"\n",
    "          f\"(Lower Bound: {results['lower_bound']}, Upper Bound: {results['upper_bound']})\")\n",
    "\n",
    "print('-----------------')\n",
    "print(\"FOR NOW, OUTLIERS NOT REMOVED, BOUNDARIES NEED TO BE ADJUSTED\")\n",
    "print(\"IDEA, RE-SCALE OUT OF BOUNDS VALUES TO THE NEAREST EXTREME: e.g: BOUND = -2 AND 2, VAL = -3 --> -2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AGGREGATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable       id        time  activity  appCat.builtin  appCat.communication  \\\n",
      "0         AS14.01  2014-02-17  0.000000           0.000                 0.000   \n",
      "1         AS14.01  2014-02-18  0.000000           0.000                 0.000   \n",
      "2         AS14.01  2014-02-19  0.000000           0.000                 0.000   \n",
      "3         AS14.01  2014-02-20  0.000000           0.000                 0.000   \n",
      "4         AS14.01  2014-02-21  0.000000           0.000                 0.000   \n",
      "...           ...         ...       ...             ...                   ...   \n",
      "1968      AS14.33  2014-05-27  0.304902         726.391              2078.403   \n",
      "1969      AS14.33  2014-05-28  2.479228        2551.046              1936.415   \n",
      "1970      AS14.33  2014-05-29  4.064507         400.034               435.105   \n",
      "1971      AS14.33  2014-05-30  4.050925        3044.030              1670.842   \n",
      "1972      AS14.33  2014-05-31  0.000000           0.000                 0.000   \n",
      "\n",
      "variable  appCat.entertainment  appCat.finance  appCat.game  appCat.office  \\\n",
      "0                        0.000             0.0          0.0          0.000   \n",
      "1                        0.000             0.0          0.0          0.000   \n",
      "2                        0.000             0.0          0.0          0.000   \n",
      "3                        0.000             0.0          0.0          0.000   \n",
      "4                        0.000             0.0          0.0          0.000   \n",
      "...                        ...             ...          ...            ...   \n",
      "1968                   124.694             0.0          0.0          0.000   \n",
      "1969                   614.706             0.0          0.0        357.909   \n",
      "1970                   136.738             0.0          0.0          0.000   \n",
      "1971                   260.220             0.0          0.0          0.000   \n",
      "1972                     0.000             0.0          0.0          0.000   \n",
      "\n",
      "variable  appCat.other  ...  appCat.travel  appCat.unknown  appCat.utilities  \\\n",
      "0                0.000  ...          0.000           0.000             0.000   \n",
      "1                0.000  ...          0.000           0.000             0.000   \n",
      "2                0.000  ...          0.000           0.000             0.000   \n",
      "3                0.000  ...          0.000           0.000             0.000   \n",
      "4                0.000  ...          0.000           0.000             0.000   \n",
      "...                ...  ...            ...             ...               ...   \n",
      "1968           142.686  ...          0.000           0.000            56.173   \n",
      "1969           529.946  ...          0.000           0.000            30.666   \n",
      "1970            29.202  ...          0.939           0.000             3.199   \n",
      "1971            52.610  ...       1052.648           8.072           232.825   \n",
      "1972             0.000  ...          0.000           0.000             0.000   \n",
      "\n",
      "variable  appCat.weather  call  circumplex.arousal  circumplex.valence  mood  \\\n",
      "0                    0.0   2.0                 NaN                 NaN   NaN   \n",
      "1                    0.0   1.0                 NaN                 NaN   NaN   \n",
      "2                    0.0   7.0                 NaN                 NaN   NaN   \n",
      "3                    0.0   2.0                 NaN                 NaN   NaN   \n",
      "4                    0.0   0.0                 NaN                 NaN   NaN   \n",
      "...                  ...   ...                 ...                 ...   ...   \n",
      "1968                 0.0   1.0           -0.600000                 0.4   6.2   \n",
      "1969                 0.0  10.0            0.000000                 1.2   8.2   \n",
      "1970                 0.0   5.0           -1.333333                 1.0   7.0   \n",
      "1971                 0.0   4.0           -0.800000                -0.4   6.8   \n",
      "1972                 0.0   0.0           -2.000000                 1.0   7.0   \n",
      "\n",
      "variable        screen  sms  \n",
      "0             0.000000  0.0  \n",
      "1             0.000000  0.0  \n",
      "2             0.000000  2.0  \n",
      "3             0.000000  3.0  \n",
      "4             0.000000  1.0  \n",
      "...                ...  ...  \n",
      "1968       4089.879001  2.0  \n",
      "1969      14320.867998  1.0  \n",
      "1970       3569.341000  1.0  \n",
      "1971       9497.646999  0.0  \n",
      "1972          0.000000  0.0  \n",
      "\n",
      "[1973 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "#agg per day\n",
    "#1C - THE RESULTING DATASET WILL BE USE FOR ML ALG THAT CAN'T HANDLE TEMPORAL DATA\n",
    "#AGGREGATION METHOD FOR NON-TIME ML ALG (WILL USE DECISION TREE OR SVM )\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data into a pandas DataFrame\n",
    "#print(table)\n",
    "\n",
    "# Set the index to 'id'\n",
    "table.set_index('id', inplace=True)\n",
    "\n",
    "# Parse the 'time' column to datetime format\n",
    "table['time'] = pd.to_datetime(table['time'])\n",
    "\n",
    "# Group the data by ID and date, and aggregate the measurements for each day\n",
    "df_daily = table.groupby([table.index, table['time'].dt.date]).agg({\n",
    "    'activity': 'sum',\n",
    "    'appCat.builtin': 'sum',\n",
    "    'appCat.communication': 'sum',\n",
    "    'appCat.entertainment': 'sum',\n",
    "    'appCat.finance': 'sum',\n",
    "    'appCat.game': 'sum',\n",
    "    'appCat.office': 'sum',\n",
    "    'appCat.other': 'sum',\n",
    "    'appCat.social': 'sum',\n",
    "    'appCat.travel': 'sum',\n",
    "    'appCat.unknown': 'sum',\n",
    "    'appCat.utilities': 'sum',\n",
    "    'appCat.weather': 'sum',\n",
    "    'call': 'sum',\n",
    "    'circumplex.arousal': 'mean',\n",
    "    'circumplex.valence': 'mean',\n",
    "    'mood': 'mean',\n",
    "    'screen': 'sum',\n",
    "    'sms': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(df_daily)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 1B IMPUTE MISSING DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable\n",
      "circumplex.arousal    705\n",
      "circumplex.valence    707\n",
      "mood                  705\n",
      "dtype: int64\n",
      "variable\n",
      "circumplex.arousal    7\n",
      "circumplex.valence    7\n",
      "mood                  7\n",
      "dtype: int64\n",
      "mood\n",
      "7.000000    275\n",
      "7.200000     98\n",
      "6.800000     83\n",
      "8.000000     73\n",
      "7.400000     72\n",
      "           ... \n",
      "7.384615      1\n",
      "7.423077      1\n",
      "7.461538      1\n",
      "7.538462      1\n",
      "6.166667      1\n",
      "Name: count, Length: 596, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/statsmodels/tsa/statespace/sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "/usr/local/lib/python3.9/site-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "/usr/local/lib/python3.9/site-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable\n",
      "mood    7\n",
      "dtype: int64\n",
      "variable         id  activity  appCat.builtin  appCat.communication  \\\n",
      "time                                                                  \n",
      "2014-02-17  AS14.01       0.0             0.0                   0.0   \n",
      "2014-02-18  AS14.01       0.0             0.0                   0.0   \n",
      "2014-02-19  AS14.01       0.0             0.0                   0.0   \n",
      "2014-02-20  AS14.01       0.0             0.0                   0.0   \n",
      "2014-02-21  AS14.01       0.0             0.0                   0.0   \n",
      "\n",
      "variable    appCat.entertainment  appCat.finance  appCat.game  appCat.office  \\\n",
      "time                                                                           \n",
      "2014-02-17                   0.0             0.0          0.0            0.0   \n",
      "2014-02-18                   0.0             0.0          0.0            0.0   \n",
      "2014-02-19                   0.0             0.0          0.0            0.0   \n",
      "2014-02-20                   0.0             0.0          0.0            0.0   \n",
      "2014-02-21                   0.0             0.0          0.0            0.0   \n",
      "\n",
      "variable    appCat.other  appCat.social  appCat.travel  appCat.unknown  \\\n",
      "time                                                                     \n",
      "2014-02-17           0.0            0.0            0.0             0.0   \n",
      "2014-02-18           0.0            0.0            0.0             0.0   \n",
      "2014-02-19           0.0            0.0            0.0             0.0   \n",
      "2014-02-20           0.0            0.0            0.0             0.0   \n",
      "2014-02-21           0.0            0.0            0.0             0.0   \n",
      "\n",
      "variable    appCat.utilities  appCat.weather      call  circumplex.arousal  \\\n",
      "time                                                                         \n",
      "2014-02-17               0.0             0.0  3.217391           -0.220524   \n",
      "2014-02-18               0.0             0.0  3.190476           -0.357586   \n",
      "2014-02-19               0.0             0.0  4.000000           -0.298779   \n",
      "2014-02-20               0.0             0.0  2.888889           -0.218118   \n",
      "2014-02-21               0.0             0.0  3.750000           -0.255205   \n",
      "\n",
      "variable    circumplex.valence  mood  screen       sms  \n",
      "time                                                    \n",
      "2014-02-17            0.712573   NaN     0.0  0.956522  \n",
      "2014-02-18            0.743969   NaN     0.0  0.523810  \n",
      "2014-02-19            0.725624   NaN     0.0  1.750000  \n",
      "2014-02-20            0.728698   NaN     0.0  1.388889  \n",
      "2014-02-21            0.753690   NaN     0.0  1.050000  \n"
     ]
    }
   ],
   "source": [
    "# 1B IMPUTE DATA WITH 2 METHODS - LINEAR INETERPOLATION AND ARIMA BASED IMPUTATION\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "#LINEAR INTERPOLATION \n",
    "data = df_daily\n",
    "nan_count = data.isna().sum()\n",
    "nan_columns_with_counts = nan_count[nan_count > 0]\n",
    "\n",
    "print(nan_columns_with_counts)\n",
    "\n",
    "for i in data.columns:\n",
    "    data[i].interpolate(method='linear', inplace=True)\n",
    "nan_count = data.isna().sum()\n",
    "nan_columns_with_counts = nan_count[nan_count > 0]\n",
    "\n",
    "print(nan_columns_with_counts)\n",
    "\n",
    "print(data['mood'].value_counts())\n",
    "data.to_csv('linear_interpolation_data.csv')\n",
    "\n",
    "\n",
    "#ARIMA METHOD\n",
    "# Load and prepare the data\n",
    "table = df_daily  # Added loading of the CSV file\n",
    "table['time'] = pd.to_datetime(table['time'])\n",
    "data = table\n",
    "data.set_index('time', inplace=True)\n",
    "\n",
    "# Identify numeric columns (excluding 'mood' as it's the target)\n",
    "numeric_columns = data.select_dtypes(include=['float64']).columns.tolist()\n",
    "if 'mood' in numeric_columns:\n",
    "    numeric_columns.remove('mood')  # Ensure mood is removed from the list\n",
    "\n",
    "def impute_with_arima(series, order=(1,1,1)):\n",
    "    \"\"\"\n",
    "    Imputes the missing values in a time series using ARIMA.\n",
    "    \n",
    "    Parameters:\n",
    "        series (pd.Series): The time series to impute.\n",
    "        order (tuple): The order (p,d,q) of the ARIMA model.\n",
    "    \n",
    "    Returns:\n",
    "        pd.Series: The time series with imputed values.\n",
    "    \"\"\"\n",
    "    # Ensure the series has regular intervals, resampling if necessary\n",
    "    series = series.resample('D').mean()\n",
    "    \n",
    "    # Drop all NaN values to find the best ARIMA parameters\n",
    "    non_na_data = series.dropna()\n",
    "    if len(non_na_data) < 3:  # Need at least 3 data points to fit ARIMA\n",
    "        return series\n",
    "    \n",
    "    try:\n",
    "        model = ARIMA(non_na_data, order=order)\n",
    "        model_fit = model.fit()\n",
    "        \n",
    "        # Predict values for the entire series, filling in the gaps\n",
    "        forecast = model_fit.predict(start=series.index[0], end=series.index[-1])\n",
    "        \n",
    "        # Replace the missing values with predictions\n",
    "        imputed_series = series.copy()\n",
    "        imputed_series[series.isna()] = forecast[series.isna()]\n",
    "    except Exception as e:\n",
    "        print(f\"Error fitting ARIMA model: {e}\")\n",
    "        return series  # Return the original series if ARIMA fitting fails\n",
    "    \n",
    "    return imputed_series\n",
    "\n",
    "# Apply ARIMA to impute missing values for each numeric column\n",
    "for col in numeric_columns:\n",
    "    data[col] = impute_with_arima(data[col])\n",
    "\n",
    "# Optionally save the imputed data\n",
    "data.to_csv('ARIMA_imputed_data.csv')\n",
    "\n",
    "# Check for remaining NaN values\n",
    "nan_count = data.isna().sum()\n",
    "nan_columns_with_counts = nan_count[nan_count > 0]\n",
    "\n",
    "# Display remaining NaN values and preview the imputed data\n",
    "print(nan_columns_with_counts)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 1 A BELOW? - PLOTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "variable_types = data['variable'].unique()\n",
    "\n",
    "for variable_type in variable_types:\n",
    "    plt.figure()\n",
    "    plt.hist(data[data['variable'] == variable_type]['value'])\n",
    "    plt.title(f'Histogram for {variable_type}')\n",
    "    plt.xlabel('Variable')\n",
    "    plt.ylabel('Value')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "variable_types = data['variable'].unique()\n",
    "\n",
    "for variable_type in variable_types:\n",
    "    plt.figure()\n",
    "    sns.boxplot(x='variable', y='value', data=data[data['variable'] == variable_type])\n",
    "    plt.title(f'Boxplot for {variable_type}')\n",
    "    plt.xlabel('Variable')\n",
    "    plt.ylabel('Value')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "data['time'] = pd.to_datetime(data['time'])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for id_value, group_data in data.groupby('id'):\n",
    "    plt.plot(group_data['time'], group_data['id'], label=id_value)\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('ID')\n",
    "plt.title('Time Distribution for Each ID')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "pivot_df = data.pivot_table(index='id', columns='variable', values='value', aggfunc='mean')\n",
    "# pivot_df = data.pivot(index='id', columns='variable', values='value')\n",
    "\n",
    "correlation_matrix = pivot_df.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# variables = ['circumplex.valence', 'appCat.unknown', 'appCat.other', 'appCat.game', 'appCat.builtin', 'mood']\n",
    "# pivot_df = data.pivot_table(index='id', columns='variable', values='value', aggfunc='mean')\n",
    "print(pivot_df)\n",
    "sns.pairplot(data=new_data, hue=\"mood_value\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO: scatterplot van de hoge correlatie\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Task 1 b\n",
    "\n",
    "<div style=\"max-width: 50%;\">\n",
    "<details>\n",
    "    <summary>Details</summary>    \n",
    "    As the insights from Task 1A will have shown, the dataset you analyze contains quite some\n",
    "    noise. Values are sometimes missing, and extreme or incorrect values are seen that are likely\n",
    "    outliers you may want to remove from the dataset. We will clean the dataset in two steps: <br><br>\n",
    "    - Apply an approach to remove extreme and incorrect values from your dataset. Describe\n",
    "    what your approach is, why you consider that to be a good approach, and describe what\n",
    "    the result of applying the approach is.<br><br>\n",
    "    â€¢ Impute the missing values using two different approaches. Describe the approaches\n",
    "    and study the impact of applying them to your data. Argue which one of the two ap-\n",
    "    proaches would be most suitable and select that one to form your cleaned dataset. Also\n",
    "    base yourself on scientific literature for making your choice.<br><br>\n",
    "    Advanced: The advanced dataset contains a number of time series, select two approaches to\n",
    "    impute missing values that are logical for such time series and argue for one of them based\n",
    "    on the insights you gain. Also consider what to do with prolonged periods of missing data in\n",
    "    a time series.\n",
    "</details>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 c\n",
    "\n",
    "<div style=\"max-width: 50%;\">\n",
    "<details>\n",
    "    <summary>Details</summary>    \n",
    "    While we now have a clean dataset, we can still take one step before we move to classification\n",
    "    or regression that can in the end help to improve performance, namely feature engineering.\n",
    "    As discussed during the lectures, feature engineering is a creative process and can involve\n",
    "    or example the transformation of values (e.g. take the log of values given a certain distribution of values) or combining multiple features (e.g. two features that are more valuable\n",
    "    combined than the two separate values). Think of a creative feature engineering approach\n",
    "    for your dataset, describe it, and apply it. Report on why you think this is a useful enrichment\n",
    "    of your dataset.<br><br>\n",
    "    Advanced: Essentially there are two approaches you can consider to create a predictive model\n",
    "    using this dataset (which we will do in the next part of this assignment): (1) use a machine\n",
    "    learning approach that can deal with temporal data (e.g. recurrent neural networks) or you\n",
    "    can try to aggregate the history somehow to create attributes that can be used in a more common machine learning approach (e.g. SVM, decision tree). For instance, you use the average\n",
    "    mood during the last five days as a predictor. Ample literature is present in the area of temporal data mining that describes how such a transformation can be made. For the feature\n",
    "    engineering, you are going to focus on such a transformation in this part of the assignment.\n",
    "    This is illustrated in Figure 1.\n",
    "\n",
    "![Figure 1: Predictive model](./images/task_1_figure_1.png)<br>\n",
    "    In the end, we end up with a dataset with a number of training instances per patient (as\n",
    "    you have a number of time points for which you can train), i.e. an instance that concerns\n",
    "    the mood at t=1, t=2, etc. Of course it depends on your choice of the history you consider\n",
    "    relevant from what time point you can start predicting (if you use a windows of 5 days of\n",
    "    history to create attributes you cannot create training instances before the 6th day). To come to this dataset, you need to:<br><br>\n",
    "    1. Define attributes that aggregate the history, draw inspiration from the scientific literature.<br>\n",
    "    2. Define the target by averaging the mood over the entire day.<br>\n",
    "    3. Create an instance-based dataset as described in Figure 1.<br>\n",
    "\n",
    "</details>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

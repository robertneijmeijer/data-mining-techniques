{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "<div style=\"max-width: 50%;\">\n",
    "<details>\n",
    "    <summary>Details</summary>    \n",
    "    As discussed during Lecture 2, the first phase of a Data Mining project typically includes getting familiar with the domain and pre-processing the dataset in a suitable manner. In this\n",
    "    part of the assignment, we will go through those steps.\n",
    "</details>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 a\n",
    "<div style=\"max-width: 50%;\">\n",
    "<details>\n",
    "    <summary>Detail</summary>    \n",
    "    Start with exploring the raw data that is available: <br><br>\n",
    "    - Notice all sorts of properties of the dataset: how many records are there, how many\n",
    "    attributes, what kinds of attributes are there, ranges of values, distribution of values,\n",
    "    relationships between attributes, missing values, and so on. A table is often a suitable\n",
    "    way of showing such properties of a dataset. Notice if something is interesting (to you,\n",
    "    or in general), make sure you write it down if you find something worth mentioning.<br><br>\n",
    "    - Make various plots of the data. Is there something interesting worth reporting? Re-\n",
    "    port the figures, discuss what is in them. What meaning do those bars, lines, dots, etc.\n",
    "    convey? Please select essential and interesting plots for discussion, as you have limited\n",
    "    space for reporting your findings.\n",
    "</details>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 b\n",
    "\n",
    "<div style=\"max-width: 50%;\">\n",
    "<details>\n",
    "    <summary>Details</summary>    \n",
    "    As the insights from Task 1A will have shown, the dataset you analyze contains quite some\n",
    "    noise. Values are sometimes missing, and extreme or incorrect values are seen that are likely\n",
    "    outliers you may want to remove from the dataset. We will clean the dataset in two steps: <br><br>\n",
    "    - Apply an approach to remove extreme and incorrect values from your dataset. Describe\n",
    "    what your approach is, why you consider that to be a good approach, and describe what\n",
    "    the result of applying the approach is.<br><br>\n",
    "    â€¢ Impute the missing values using two different approaches. Describe the approaches\n",
    "    and study the impact of applying them to your data. Argue which one of the two ap-\n",
    "    proaches would be most suitable and select that one to form your cleaned dataset. Also\n",
    "    base yourself on scientific literature for making your choice.<br><br>\n",
    "    Advanced: The advanced dataset contains a number of time series, select two approaches to\n",
    "    impute missing values that are logical for such time series and argue for one of them based\n",
    "    on the insights you gain. Also consider what to do with prolonged periods of missing data in\n",
    "    a time series.\n",
    "</details>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 c\n",
    "\n",
    "<div style=\"max-width: 50%;\">\n",
    "<details>\n",
    "    <summary>Details</summary>    \n",
    "    While we now have a clean dataset, we can still take one step before we move to classification\n",
    "    or regression that can in the end help to improve performance, namely feature engineering.\n",
    "    As discussed during the lectures, feature engineering is a creative process and can involve\n",
    "    or example the transformation of values (e.g. take the log of values given a certain distribution of values) or combining multiple features (e.g. two features that are more valuable\n",
    "    combined than the two separate values). Think of a creative feature engineering approach\n",
    "    for your dataset, describe it, and apply it. Report on why you think this is a useful enrichment\n",
    "    of your dataset.<br><br>\n",
    "    Advanced: Essentially there are two approaches you can consider to create a predictive model\n",
    "    using this dataset (which we will do in the next part of this assignment): (1) use a machine\n",
    "    learning approach that can deal with temporal data (e.g. recurrent neural networks) or you\n",
    "    can try to aggregate the history somehow to create attributes that can be used in a more common machine learning approach (e.g. SVM, decision tree). For instance, you use the average\n",
    "    mood during the last five days as a predictor. Ample literature is present in the area of temporal data mining that describes how such a transformation can be made. For the feature\n",
    "    engineering, you are going to focus on such a transformation in this part of the assignment.\n",
    "    This is illustrated in Figure 1.\n",
    "\n",
    "![Figure 1: Predictive model](./images/task_1_figure_1.png)<br>\n",
    "    In the end, we end up with a dataset with a number of training instances per patient (as\n",
    "    you have a number of time points for which you can train), i.e. an instance that concerns\n",
    "    the mood at t=1, t=2, etc. Of course it depends on your choice of the history you consider\n",
    "    relevant from what time point you can start predicting (if you use a windows of 5 days of\n",
    "    history to create attributes you cannot create training instances before the 6th day). To come to this dataset, you need to:<br><br>\n",
    "    1. Define attributes that aggregate the history, draw inspiration from the scientific literature.<br>\n",
    "    2. Define the target by averaging the mood over the entire day.<br>\n",
    "    3. Create an instance-based dataset as described in Figure 1.<br>\n",
    "\n",
    "</details>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
